# 11月4日组会汇报

## 插值

### Akima 自适应样条插值。

对 Lat、Lon、Speed、Course 逐列插值；时间步长统一为10秒；仅在原始[min, max]区间内插值，不外推。

适合不均匀采样数据，C1连续、局部性强，对拐点和端点更稳，较少振荡与过冲。
生成等时序列，便于轨迹对齐、统计与可视化。

#### 流程

批量读取CSV，要求含UnixTime；按UnixTime排序并设为索引；不足100点跳过。

在原始时间范围内生成10秒新时间网格。

将索引转为相对秒；若时间不严格递增，对相等/倒序点加0.001秒保证单调。

使用Akima对各列插值到新网格。

若插值后点数 > 原始1.5倍，则保存结果CSV（补回UnixTime为首列）并输出经纬度散点对比图；否则跳过并记录原因。

_备注：当前未对Course的环变量特性或Speed非负性做特殊约束，仅作区间内插值。_

#### 结果

仅展示部分拐点处插值效果。

<div align=center><img src="25.11.5IMG/412591040_2_comparison.png"/></div>

<div align=center><img src="25.11.5IMG/413207810_0_comparison.png"/></div>

<div align=center><img src="25.11.5IMG/413253910_5_comparison.png"/></div>

<div align=center><img src="25.11.5IMG/413379210_0_comparison.png"/></div>

## 多步预测

目标：学习10秒等时序的船舶轨迹模式，用4分钟历史预测未来4分钟经纬度（24步），并支持递归多步预测。

### RMSTPNet

基于Transformer的递归多步时间序列预测网络（Recursive Multi-step Time Series Prediction Network）。

#### 模型结构

- 输入与输出
  - 输入: [B, 24, 4]（10s间隔4分钟，特征=Lon, Lat, Speed, Course，均已归一化）
  - _过去4分钟的轨迹数据，间隔10秒一个点，共24个点；每个点有4个数。_
  - 输出: [B, 24, 2]（未来4分钟的 [Lon, Lat]，三段拼接：6+12+6）
  - _未来4分钟的位置（经度、纬度），同样每10秒一个点，共24个点。模型分三段给出：前1分钟、1–3分钟、3–4分钟，最后拼成完整序列。_
````python
# 配置中的窗口长度（10s间隔 → 24步 = 4分钟）
'hist_len': 24,
'pred_len': 24,
...
# 数据集切片处：history=24步×4特征，target=24步×2坐标
hist = features[start:start + self.hist_len]                 # [24, 4]
pred = features[start + self.hist_len:start + self.hist_len + self.pred_len, :2]  # [24, 2]
history = torch.FloatTensor(hist)
target = torch.FloatTensor(pred)
````

- 模块组成
  - 特征编码器（MLP）（两层全连接）
    - 4 → 64 → 128，激活ReLU，Dropout=0.3
    - _把每个时刻的4个原始数，先提炼到64维，再到128维，配合ReLU和Dropout_
    - 作用：将4维手工特征映射到更高维时序嵌入
````python
self.feature_encoder = nn.Sequential(
    nn.Linear(input_dim, 64),
    nn.ReLU(),
    nn.Dropout(dropout),
    nn.Linear(64, hidden_dim),
    nn.ReLU(),
    nn.Dropout(dropout)
)
````
  - 时序建模（双向GRU）
    - 2层、hidden=256、双向，输出步长特征为512维
    - 作用：捕获历史序列的双向依赖与动态模式
````python
self.temporal_model = nn.GRU(
    input_size=hidden_dim,
    hidden_size=gru_hidden,
    num_layers=2,
    batch_first=True,
    bidirectional=True,
    dropout=dropout
)
````
  - 注意力机制（时间加权汇聚）
    - 512 → 256 → 1，Softmax 时间维，得到加权和的上下文向量 [B, 512]
    - _给24个历史时刻自动打分，分数高代表更关键；按分数做加权汇总，得到一个“摘要向量”_
    - 作用：突出对预测最关键的历史时刻
````python
self.attention = nn.Sequential(
    nn.Linear(gru_hidden * 2, gru_hidden),
    nn.Tanh(),
    nn.Linear(gru_hidden, 1)
)
# 使用时：softmax打分并加权求和为上下文摘要
attention_weights = torch.softmax(self.attention(temporal_out), dim=1)  # [B,24,1]
context = torch.sum(attention_weights * temporal_out, dim=1)            # [B,512]
````
  - 多尺度预测头（3个分支）
    - Immediate: 512 → 256 → 6×2（0–1分钟）
    - Short-term: 512 → 256 → 12×2（1–3分钟）
    - Medium-term: 512 → 256 → 6×2（3–4分钟）
    - _基于“摘要向量”，分别预测三段未来：0–1分钟、1–3分钟、3–4分钟_
    - 作用：分尺度学习不同时间跨度的轨迹变化，短期变化快、长期更平稳，分开学更稳更准，最后拼接成24点
````python
self.multiscale_heads = nn.ModuleDict({
    'immediate': self._make_prediction_head(gru_hidden * 2, 6),   # 0-1分钟
    'short_term': self._make_prediction_head(gru_hidden * 2, 12), # 1-3分钟
    'medium_term': self._make_prediction_head(gru_hidden * 2, 6)  # 3-4分钟
})
def _make_prediction_head(self, input_dim, pred_points):
    return nn.Sequential(
        nn.Linear(input_dim, 256),
        nn.ReLU(),
        nn.Dropout(0.2),
        nn.Linear(256, pred_points * 2)  # 每点预测[lon, lat]
    )
````

- 前向数据流与张量形状
  - 输入 x[B,24,4]
  - _读入24个历史点（每点4个特征）_
  - 编码: [B,24,128]
  - _对每个点做特征提炼（更高维、更有信息）_
  - GRU: [B,24,512]
  - _用双向GRU理解整段历史（结合前后文）_
  - 注意力加权: 权重[B,24,1] → 上下文[B,512]
  - _用注意力挑出关键时刻，汇成摘要_
  - 三头预测: [B,6,2]、[B,12,2]、[B,6,2] → 拼接[B,24,2]
  - _三个分支分别产出近、中、远三段未来位置，拼成完整4分钟预测_
````python
encoded = self.feature_encoder(current_input)        # [B,24,128]
temporal_out, _ = self.temporal_model(encoded)       # [B,24,512]
attention_weights = torch.softmax(self.attention(temporal_out), dim=1)  # [B,24,1]
context = torch.sum(attention_weights * temporal_out, dim=1)            # [B,512]
predictions = {
    'immediate': self.multiscale_heads['immediate'](context).view(batch_size, 6, 2),
    'short_term': self.multiscale_heads['short_term'](context).view(batch_size, 12, 2),
    'medium_term': self.multiscale_heads['medium_term'](context).view(batch_size, 6, 2)
}
full_prediction = torch.cat([
    predictions['immediate'],
    predictions['short_term'],
    predictions['medium_term']
], dim=1)  # [B,24,2]
````

- 递归多步预测机制（怎么滚到更久的将来）
  - 循环 step=recursive_steps+1 次；每次用本轮预测的24点构造下一轮输入：
  - _先预测未来4分钟；再把这24个预测点当“新的历史”继续预测：_
    - Lon/Lat：使用预测坐标
    - _经度/纬度：直接用上次的预测结果。_
    - Speed：复用历史速度的均值
    - _速度：用历史速度的平均值近似。_
    - Course：由相邻预测点位移 atan2 计算后/360 归一化
    - _航向：用相邻预测点的位移方向计算出角度（再做归一化）。_
  - 作用：在4分钟基础上滚动扩展更多未来时长（默认1次 → 8分钟总预测）
````python
# 递归循环
for step in range(recursive_steps + 1):
    ...  # 预测得到 full_prediction
    if step < recursive_steps:
        current_input = self._build_recursive_input(current_input, full_prediction)

def _build_recursive_input(self, history_input, prediction):
    return self._compute_features_from_predictions(prediction, history_input)

def _compute_features_from_predictions(self, pred_coords, history_features):
    lon = pred_coords[:, :, 0:1]
    lat = pred_coords[:, :, 1:2]
    # 速度：复用历史速度均值
    hist_speed = history_features[:, :, 2:3].mean(dim=1, keepdim=True).expand(-1, pred_coords.size(1), -1)
    # 航向：由相邻预测位移计算方向角并/360归一化
    delta = pred_coords[:, 1:, :] - pred_coords[:, :-1, :]
    first_delta = delta[:, 0:1, :]
    all_deltas = torch.cat([first_delta, delta], dim=1)
    course_rad = torch.atan2(all_deltas[:, :, 1], all_deltas[:, :, 0])
    course_deg = (course_rad * 180 / np.pi) % 360
    course_norm = (course_deg / 360.0).unsqueeze(-1)
    return torch.cat([lon, lat, hist_speed, course_norm], dim=-1)  # [B,24,4]
````

- 设计动机
  - MLP 提升表征维度；BiGRU 捕获时序依赖；注意力聚焦关键历史；多尺度头提升不同时间跨度的拟合能力；递归机制支持更长时域外推。
  - _分段预测：把“近、中、远”拆开学，难点各自解决，整体更稳。_
  - _注意力：自动把精力放在转弯、变速等关键片段。_
  - _双向记忆：既不丢趋势，也不丢细节。_
  - _递归扩展：先拿近未来，再滚动到更长时间范围。_

#### 损失函数与优化

